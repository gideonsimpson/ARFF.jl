# Example: Kammonen Test 5
Here we will fit data generated by the following function $f: \mathbb{R}^d \to \mathbb{R}$:
\begin{align}
    \boldsymbol{x}_m &\sim \mathcal{N}(\boldsymbol{0}, Id), \\
    y_m &= f(\boldsymbol{x}_m), \\
    f(\boldsymbol{x}) &= Si(\frac{[\boldsymbol{x}B]_1}{a}) exp(-\frac{||\boldsymbol{x}B||_2^2}{2}),
\end{align}
for row vector $\boldsymbol{x}_m \in \mathbb{R}^{1 \times d}$ and where $[\boldsymbol{x}B]_1$ denotes the first component of the vector $\boldsymbol{x}B$ with $B$ being the rotation matrix defined as follows:

$$
B = \begin{bmatrix}
0.8617 & 0.4975 & -0.0998 & -0.0000 \\
0.3028 & -0.5246 & -0.0000 & 0.7957 \\
0.0865 & 0.0499 & 0.9950 & 0.0000 \\
0.3978 & -0.6891 & -0.0000 & -0.6057 \\
\end{bmatrix}.
$$

In our example, we will use $a = 10^{-2}$.

```@setup ex4
using Revise
using ARFF
using Random
using Statistics
using LinearAlgebra
using SpecialFunctions
using Plots
using Distributions
```

## Define $B$ and $f(x)$
```@example ex4

Bt = [  0.8617 0.4975 -0.0998 -0.0;
        0.3028 -0.5246 -0.0000 0.7957;
        0.0865 0.0499 0.9950 0.0000;
        0.3978 -0.6891 -0.0000 -0.6057];

B = (Bt')|>collect;
b1 = B[1,:];

a = 1e-2;
f(x) = sinint(b1⋅x/ a) * exp(-0.5 * (norm(B*x,2)^2));
```

## Generate data
```@example ex4
dx = 4;
nx = 10^3;
Random.seed!(100) # for reproducibility
x = [randn(dx) for _ in 1:nx];
y = f.(x);
data = DataSet(x, y);
```

## Define Training Parameters
```@example ex4
@show K = 2^8;
Random.seed!(200) # for reproducibility

F0 = FourierModel([1.0 for _ in 1:K], [10 * rand(dx) for _ in 1:K], SigmoidActivation)
δ = 0.1 # rwm step size
λ = 1e-1 # regularization
n_epochs = 10^3 # number of epochs
n_rwm_steps = [5, 5, 1] # number of steps between full β updates for each scenario
n_burn = n_epochs ÷ 10 # use 10% of the run for burn in

batch_size = 10^3;
```

## Define solver and resampler for each R value
```@example ex4
linear_solver! = (β, ω, x, y, S, epoch) -> solve_normal!(β, S, y, λ=λ) # define linear solver

rwm_sampler = [AdaptiveRWMSampler(F0, linear_solver!, n_rwm_steps_, n_burn, δ) for n_rwm_steps_ in n_rwm_steps]; #define rwm sampler for each R.

R_vals = [0.0, 0.75, 1.0] # effective sample size thresholds

mutate_rwm1!(F, x, y, S, n) = ARFF.rwm!(F, rwm_sampler[1], x, y, S, n) # mutate rwm for R=0.0
mutate_rwm2!(F, x, y, S, n) = ARFF.rwm!(F, rwm_sampler[2], x, y, S, n) # mutate rwm for R=0.75
mutate_rwm3!(F, x, y, S, n) = ARFF.rwm!(F, rwm_sampler[3], x, y, S, n) # mutate rwm for R=1.0

mutate_rwm_array = [mutate_rwm1!, mutate_rwm2!, mutate_rwm3!]

resampler! = [(F, x, y, S, epoch) -> ARFF.resample!(F, x, y, S, epoch, rwm_sampler[i].linear_solve!, R=R_vals[i]) for i in 1:3] # resampler for every R value

solver = [ARFFSolver(rwm_sampler[i].linear_solve!, mutate_rwm_array[i], resampler![i], mse_loss) for i in 1:3]; # solver for every resampler
```

## Train $R=0.0$ Network
```@example ex4
Random.seed!(1000) # for reproducibility
G1 = deepcopy(F0)
loss1 = train_arff!(G1, Iterators.cycle([data]), batch_size, solver[1], n_epochs, show_progress=true);
```

## Train $R=0.8$ Network
```@example ex4
Random.seed!(1000) # for reproducibility
G2 = deepcopy(F0)
loss2 = train_arff!(G2, Iterators.cycle([data]), batch_size, solver[2], n_epochs, show_progress=true);
```

## Train $R=1.0$ Network
```@example ex4
Random.seed!(1000) # for reproducibility
G3 = deepcopy(F0)
loss3 = train_arff!(G3, Iterators.cycle([data]), batch_size, solver[3], n_epochs, show_progress=true);
```

## Compare Loss Curves
```@example ex4
using LaTeXStrings
plot(1:n_epochs, loss1, xscale=:log10, yscale = :log10, label = L"R=0.0", legend = :bottomleft)
plot!(1:n_epochs, loss2, label = L"R=0.75")
plot!(1:n_epochs, loss3, label = L"R=1.0")
xlabel!("number of iterations")
ylabel!("MSE")
```

It is worth noting that parameters can be tuned in the above example to get more accurate results. We have noticed that the resampling method shows improvement in some scenarios, but performs similarily to the $R=0.0$ case in others. The performance increase is loosly related to scenarios where we are fitting large data sets and using large $K$ values.

