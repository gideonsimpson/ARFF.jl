# Example: Kammonen Test 5
Here we will fit data generated by the following function $f: \mathbb{R}^d \to \mathbb{R}$:
\begin{align}
    \boldsymbol{x}_m &\sim \mathcal{N}(\boldsymbol{0}, Id), \\
    y_m &= f(\boldsymbol{x}_m), \\
    f(\boldsymbol{x}) &= Si(\frac{[\boldsymbol{x}B]_1}{a}) exp(-\frac{||\boldsymbol{x}B||_2^2}{2}),
\end{align}
for row vector $\boldsymbol{x}_m \in \mathbb{R}^{1 \times d}$ and where $[\boldsymbol{x}B]_1$ denotes the first component of the vector $\boldsymbol{x}B$ with $B$ being the rotation matrix defined as follows:

$$
B = \begin{bmatrix}
0.8617 & 0.4975 & -0.0998 & -0.0000 \\
0.3028 & -0.5246 & -0.0000 & 0.7957 \\
0.0865 & 0.0499 & 0.9950 & 0.0000 \\
0.3978 & -0.6891 & -0.0000 & -0.6057 \\
\end{bmatrix}.
$$

In our example, we will use $a = 10^{-2}$.

```@setup ex4
using Revise
using ARFF
using Random
using Statistics
using LinearAlgebra
using SpecialFunctions
using Plots
using Distributions
```

## Define $B$ and $f(x)$
```@example ex4

Bt = [  0.8617 0.4975 -0.0998 -0.0;
        0.3028 -0.5246 -0.0000 0.7957;
        0.0865 0.0499 0.9950 0.0000;
        0.3978 -0.6891 -0.0000 -0.6057];

B = (Bt')|>collect;
b1 = B[1,:];

a = 1e-2;
f(x) = sinint(b1⋅x/ a) * exp(-0.5 * (norm(B*x,2)^2));
```

## Generate data
```@example ex4
dx = 4;
nx = 10^4;
Random.seed!(100) # for reproducibility
x = [randn(dx) for _ in 1:nx];
y = f.(x);
data = DataSet(x, complex.(y));
```

## Define Training Parameters
```@example ex4
@show K = 2^7;
Random.seed!(200) # for reproducibility
# F0 = FourierModel([1.0 * randn() for _ in 1:K], [randn(d) for _ in 1:K])

ω0_mean = zeros(dx)
ω0_cov = 10^2 * I(dx)
ω0_dist = MvNormal(ω0_mean, ω0_cov)
F0 = FourierModel([1.0 for _ in 1:K], [rand(ω0_dist) for _ in 1:K])
δ = 0.1 # rwm step size
λ = 1e-1 # regularization
n_epochs = 10^4 # number of epochs
n_rwm_steps = 1 # number of steps between full β updates
n_burn = n_epochs ÷ 10 # use 10% of the run for burn in

batch_size = 10^3;
```

## Define solver and resampler for each R value
```@example ex4
linear_solver! = (β, ω, x, y, S, epoch) -> solve_normal!(β, S, y, λ=λ)

rwm_sampler = AdaptiveRWMSampler(F0, linear_solver!, n_rwm_steps, n_burn, δ);

mutate_rwm!(F, x, y, S, n) = ARFF.rwm!(F, rwm_sampler, x, y, S, n)

R_vals = [0.0, 0.8, 1.0]

resampler! = [(F, x, y, S, epoch) -> ARFF.resample!(F, x, y, S, epoch, rwm_sampler.linear_solve!, R=R_) for R_ in R_vals] # resampler for every R value

solver = [ARFFSolver(rwm_sampler.linear_solve!, mutate_rwm!, resampler!_, mse_loss) for resampler!_ in resampler!]; # solver for every resampler
```

## Train $R=0.0$ Network
```@example ex4
Random.seed!(1000) # for reproducibility
G1 = deepcopy(F0)
loss1 = train_arff!(G1, Iterators.cycle([data]), batch_size, solver[1], n_epochs, show_progress=true);
```

## Train $R=0.8$ Network
```@example ex4
Random.seed!(1000) # for reproducibility
G2 = deepcopy(F0)
loss2 = train_arff!(G2, Iterators.cycle([data]), batch_size, solver[2], n_epochs, show_progress=true);
```

## Train $R=1.0$ Network
```@example ex4
Random.seed!(1000) # for reproducibility
G3 = deepcopy(F0)
loss3 = train_arff!(G3, Iterators.cycle([data]), batch_size, solver[3], n_epochs, show_progress=true);
```

## Compare Loss Curves
```@example ex4
using LaTeXStrings
plot(1:n_epochs, loss1, xscale=:log10, yscale = :log10, label = L"R=0.0", legend = :bottomleft)
plot!(1:n_epochs, loss2, label = L"R=0.8")
plot!(1:n_epochs, loss3, label = L"R=1.0")
xlabel!("number of iterations")
ylabel!("MSE")
```



